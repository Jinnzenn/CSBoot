# 操作系统

## 计算机架构组成/计算机组成原理
（硬件）

### 存储结构

- 高速缓存 I/O

	- caching

### 控制器

- 指针IP 
IR + PC

  IR的全称应该是Instructinon register
  指令寄存器是用来存放指令的，存放当前正在执行的指令，包括指令的操作码，地址码，地址信息标示了CPU的执行操作
  PC的全称是program counter
  程序计数器，是用来计数的，指示指令在存储器的存放位置，也就是个地址信息。

### 运算器

### 输入

### 输出

## 计算机系统运行的本质：

### 取指令执行

### 【应用程序】
----------------------
【操作系统】
----------------------
【计算机硬件】

## 操作系统启动
power on

### 总体两个步骤：
1、将操作系统代码数据从磁盘存储读取到内存
2、完成操作系统的初始化

### 硬件水平支持

- 主板硬件结构：
ROM BIOS

	- 磁盘上：引导扇区0x7c00

		- 磁盘0磁道0扇区0

	- 完成寻址0xFFFF0，读取操作系统代码数据

- CS:IP

  CPU在访问内存的时候要由相关部件提供内存单元的段地址和偏移地址，送入地址加法器合成物理地址。段寄存器提供段地址。8086CPU有4个段寄存器：CS、DS、ES、SS。典型的提供段地址和偏移地址的寄存器为CS和IP寄存器。也就是说，CPU会将CS:IP合成的物理地址指向的内容当作指令执行。CPU执行指令的步骤一般是：
  
  （1）将CS、IP中的内容送入地址加法器（段地址*16+偏移地址）合成物理地址。
  
  （2）地址加法器将物理地址送入输入输出控制电路
  
  （3）输入输出控制电路将物理地址送上地址总线
  
  （4）然后CPU从物理地址指向的内存单元读取机器指令，并将机器指令通过数据总线送入CPU的输入输出控制电路。
  
  （5）输入输出控制电路将读取的指令送入指令缓冲器，同时IP的内容更新为原内容加指令长度。
  
  （6）然后，执行控制器执行机器指令，并将执行后的内容送入相应的寄存器。

### 启动过程

- 操作系统的代码布局：
【Bootset | Setup | System（包括head.s main.c）等
硬件BIOS寻址到操作系统bootset模块，bootset模块读取setup模块，setup模块完成引入system模块的准备工作，system模块完成操作系统本身的各项初始化工作。
- 机器代码（面向硬件）-汇编代码 - C语言代码的转换：
1、as86汇编，产生16位代码的Intel 8086汇编，bootset 和 setup 时使用
2、GNU as汇编，产生32位代码，使用AT&T的V语法
system模块时使用
3、内嵌汇编，gcc编译x.c会产生中间结果as汇编文件x.s
- bootset模块

	- 将操作系统的setup模块读取到引导扇区
BIOS 13号中断 读取 system.s 模块

- setup模块

	- 完成OS启动前的设置

		- 接入硬件参数

			- 取光标位置
			- BIOS 15号中断，获取内存大小，用于system.s的内存管理模块（内存大小超过1Mb，称为扩展内存参数）
			- 显卡参数
			- 根设备号

		- 将system.s代码移至0地址，初始化GDT表（global destination table)，用于寻址
另外也有 IDT表
		- 将操作系统切换到保护模式

			- 切换是通过寄存器cr0的最后一位来决定。切换完成后，运用高级指令 
jmpi 0,8
跳转到0地址处，进入system.s中的head.s部分
			- 实模式

				- 16位汇编代码、16位寻址模式，CS:IP 使用的16进制

			- 保护模式

				- 32位汇编代码，32位寻址模式
				- 保护模式下的地址翻译

					- CS:IP（选择子）被用于寻GDT表，选出基址，再进行寻址。具体实现由硬件完成。

				- 保护模式下的中断处理

					- gdt_48，保护模式中断函数表

- system模块

	- 完成操作系统代码的初始化

		- head.s

			- makefile

				- 将C代码编译，完成可执行的镜像文件
（image），image位置最终在0磁道0扇区

			- 包括了after_page_tables段代码

			  after_page_tables:
			  	pushl $0	   pushl $0    pushl $0    pushl $L6
			  	pushl $_main    jmp     set_paging
			  L6L:  jmp  L6
			  setup_paging : [设置页表代码]    ret

				- 设置页表

		- main.c

			- 完成各项系统功能的初始化，包括内存、中断、设备、时钟、CPU

				- 举例：内存
void mem_init（long begin_mem, long end_mem）
{
【使用了mem_map数据结构】

			- 完成了设备表格的初始化， 等待用户的设备使用

- 打开了图形化系统桌面。或者启动了shell程序，即/bin/sh
if(!fork()) {exec(cmd);}

## 操作系统接口
OS interface

### 概念

- 用户如何使用计算机？
1、命令行
2、图形按钮
3、应用程序
- 什么是操作系统接口：
操作系统接口是操作系统提供给应用程序使用的一些函数，C语言程序中可以使用它们。
操作系统接口表现为函数调用，又由系统提供，所以称为系统调用（system_call）

#include <stdio.h>
int main(int argc, char * argv[]){
    printf("ECHO:%S\N", ARGV[1]);    #printf就是系统提供的函数
}

### 设计标准

- 系统调用，POSIX （portable OS interface of Unix），不同操作系统提供了统一的操作系统接口标准，比如
任务管理： fork 创建一个进程
文件系统 ： open  打开一个文件或目录

	- 阻塞调用是指调用结果返回之前，当前线程会被挂起。函数只有在得到结果之后才会返回。有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已。例如，我们在CSocket中调用Receive函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回。而此时，当前线程还会继续处理各种各样的消息。如果主窗口和调用函数在同一个线程中，除非你在特殊的界面操作函数中调用，其实主界面还是应该可以刷新。socket接收数据的另外一个函数recv则是一个阻塞调用的例子。当socket工作在阻塞模式的时候，如果没有数据的情况下调用该函数，则当前线程就会被挂起，直到有数据为止。
	- 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。
	- 对象的阻塞模式和阻塞函数调用 对象是否处于阻塞模式和函数是不是阻塞调用有很强的相关性，但是并不是一一对应的。阻塞对象上可以有非阻塞的调用方式，我们可以通过一定的API去轮询状态，在适当的时候调用阻塞函数，就可以避免阻塞。而对于非阻塞对象，调用特殊的函数也可以进入阻塞调用。函数select就是这样的一个例子。

### 实现

- 将内核程序和用户程序隔离：
硬件设计上，区分内核态和用户态
内存管理上，区分内核段和用户段

	- GDT跳转时，检查当前位置层级，仅在 DPL>=CPL（目标>=当前，例如3>=0）时才执行跳转。
	- CS:IP表示当前指令，CS的最低两位数，0为内核段，3为用户段
	- 结果：
jmp指令 mov指令不能直接访问系统内核，有且仅有几个中断指令int可以进入系统内核

		- 举例，以printf的解释执行为例说明系统调用的实现过程
printf用户调用--print展开为包括int 0x80的系统调用--system_call中断处理--查表system_call（IDT表）得到系统提供的接口--执行接口程序

		  main()
		  {
		  	eax = 72;
		  	int 0x80;
		  }
		  ----------------------------
		  _system_call:
		  	call sys_whoami
		  // sys_call_table + eax*4
		  ----------------------------
		  sys_whoami()
		  {
		  	printk(100,8)
		  }
		  
		  100:"words and letters"

### Shell | GUI

- 处于用户态程序的最低层次

## 操作系统的历史发展
中的关键技术
history of OS

### 1955-1965
IBSYS

- 批处理操作系统
Batch System

### 1965-1980
OS/360

- 多功能多用途
- 多进程程序和进程管理概念
- 作业之间的切换和调度成为核心

### 1965-1980
MULTICS

- timesharing 分时系统
- 多人同时使用
- 多进程，且引入资源复用思想，例如虚拟内存

### 1980-1990
UNIX

- 简化版MULTICS

### 1990-2000
IBM-PC
Linux

### CP/M
--QDOS
--MS-DOS

### WINDOWS

- 图形界面、文件管理、开发环境

### 操作系统的树状结构
the tree of OS

## 核心图像

### 进程view

- CPU管理

	- 工作原理

		- 取指令执行

			- 启动过程

				- 设置好 PC ，程序执行的起始位置

			- 从某一地址开始，自动取指令顺序执行

	- 进程-进程管理
并发：
多道程序，交替执行
分配资源，进行调度

	  多核： multiprocessing, 意思就是多重处理， 多个cpu同时干活。
	  
	          多进程： multiprogramming， 也可以近似认为是multitasking,  意思就是多道程序设计。 单个cpu并发干活， 在不同的进程间切换。
	  
	          多线程： multithreading,  这个就是我们通常说的多线程， 单个cpu并发干活， 在同一个进程的线程间切换。

		- 并行和并发

			- 硬件并行：
多处理器系统，两个及以上CPU共享一块物理内存，同时执行多个程序
			- 伪并行：
单个CPU快速地在不同进程间切换，形成的多个程序同步运行的效果，也叫做并发

				- 这种系统设计思路，叫做多道程序设计。
				- 通常单个进程不受其他进程运行速度的影响
				- 精确的多程序并行模型要使用排队论

		- 进程的概念

			- 进程模型

				- “进程” process 的概念：
运行的程序和静态的程序不同，引入“进程”的概念。
-程序：
作为静态文件存储在计算机系统的硬盘等存储空间中
-进程：
处于动态条件下由操作系统维护的系统资源管理实体
1. 能更好地描述并发，程序不能
2. 由程序和数据两方面组成，是竞争计算机系统有限资源的基本单位，也是进程处理机调度的基本单位
3. 程序是静态的概念，进程是程序在处理机上一次执行的过程，是动态的
4. 进程有生存周期，是短暂的，程序是长久的
5. 一个程序可以作为多个进程的运行程序，一个进程也可以运行多个程序

					- 进程 = 资源（地址空间） + 指令执行序列

				- 进程：正在执行的程序，每个程序有自己独立的地址空间，地址空间中包含可执行的程序、程序数据和栈存储结构。

进程是一个容纳了程序执行所需要的所有信息的容器。
可以抽象为2部分 控制线程（操作序列）+地址空间

			- 进程的实现

				- 一个进程运行的所有有关信息，存储于进程表process table中，或者叫PCB 进程控制块，包括内存分配情况、寄存器状态、程序计数器、堆栈指针、调度信息、打开文件状态等；信息分为三部分：进程管理、存储管理、文件管理。每个进程的进程控制块PCB占用一个进程表表项，包括了进程状态的重要信息。
操纵系统通过中断的方式切换进程，操作系统是由中断驱动的。
				- 系统中断：
    硬件压入堆栈程序计数器等，对当前进程来说，通常是在进程表项中。
    硬件从中断向量装入新的程序计数器。
    汇编语言过程保存寄存器的值。
    汇编语言过程设置新的堆栈。
    C中断服务例程运行（典型的读和缓冲输入）
    调度程序决定下一个将运行的进程
    C过程返回至汇编代码
    汇编语言过程开始运行新的当前进程

			- 创建进程

				- Unix统一通过系统调用fork()创建
4种事件：
1、系统初始化
2、进程创建子进程，此时子进程是父进程的精确副本（完全一样）。fork调用返回子进程的进程标识符—-相当于指向子进程的指针，在子进程中此值为0（因为子进程没有他的子进程），使用这个PID可以区分两个进程。
3、用户请求创建，比如点击程序
4、批处理作业初始化

					- 每个进程都有PID（process identifier 进程标识符)，子进程虽然基本复制了父进程，地址空间上可能有共享的部分，但PID不同。

			- 终止进程

				- 1、进程运行完毕，自动退出
2、进程出错退出，比如shell执行不存在的文件
3、非法指令、内存引用错误等，进程严重出错，向系统申请中断
4、被其他进程的系统调用kill()终止

			- 进程的层次结构

				- Unix中进程具有父子关系，Windows中没有，父进程仅持有子进程的句柄
				- 观察：
多进程图像从计算机启动到关机一直存在
进程中启动子进程或新的进程

				  int main(int argc, char * argv[]){
				  	while(1){
				  		scanf("%s",cmd);
				  		if(!fork(){
				  			exec(cmd);
				  		}
				  		wait();
				  	}
				  }

			- 进程的状态

				- 进程由于等待输入或者其他原因被挂起
				-     运行态（进程实际占用cpu）
    就绪态（条件全部具备，因为其他进程在运行而暂时停止）
    阻塞态/等待态（因为缺少运行所需条件而停止，外部条件不满足不运行，如等待I/O）

		- 并发：
单个进程内的多线程

			- 线程的概念

				- 在同一个进程中运行多个线程，是对在一台计算机上运行多个进程的模拟。

每个线程都可以访问进程地址空间的每一个内存地址，线程之间不设保护，不可能也没必要。

线程和进程一样拥有运行，就绪，阻塞，终止状态。

					- 共享：堆，全局变量，静态变量，文件
私有：栈，寄存器

				- 进程和线程的区别

					- 线程是资源调度的基本单位，进程是资源分配的基本单位，进程用于把资源集中到一起，而线程是CPU上被调度的实体。

			- 引进线程：
1、将程序分解，是程序设计模型简单，程序运行时有多项活动同时进行，多个并行实体共享同一个地址空间和所有可用数据（例如文字处理的时候，多个线程对文件进行交互，格式处理，备份）。运行时，部分活动可能阻塞，多线程允许多项活动彼此重叠，加快程序进行。
2、部分情况下，有共享资源的需求，只要切换指令流，不用切换资源。
3、比进程更加轻量级，更容易创建和撤销。进程之间有切换代价，而创建和销毁一个线程比进程快10-100倍；
4、如果存在大量的计算和大量的I/O处理，允许重叠进行会加快速度，提高性能。

				- 在进程中，将资源和指令分开，一项资源（地址空间）+多个指令执行序列。保留了并发的优点，减少了进程切换代价，不需要在内存方面切换映射表，仅仅PC指针切换

单个线程有自己的tid、堆栈指针、程序计数器等

			- 新建线程 | 线程销毁

				- POSIX标准 pthread
thread_create
thread_exit
thread_yield

			- 用户级线程实现
user thread

				- 从广义上来讲，一个线程只要不是内核线程，就可以认为是用户线程（User Thread,UT），因此，从这个定义上来讲，轻量级进程也属于用户线程，但轻量级进程的实
现始终是建立在内核之上的，许多操作都要进行系统调用，效率会受到限制。而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存
在的实现。 用户线程的建立、 同步、 销毁和调度完全在用户态中完成，不需要内核的帮助。

					- 用户态-运行时系统
					- 如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。 这种进程与用户线程之间1：N的关系称为一对多的线程模型

				- 优点：
1、线程切换时不需要陷入内核，切换上下文，刷新高速缓存等，切换代价小；
2、可以有定制的切换调度算法
3、记录线程信息的线程表存放在进程当中，线程数量大时，不用担心用于存放的内存不足的问题。可扩展性更好。
4、可以在不支持线程的操作系统上运行。 

					- 缺点：
1、单个线程除非有thread_yield退出机制等，否则在单独的进程中没有类似内核态中时钟中断，一个线程可能永久运行的。解决 
------方法：向运行时系统申请每秒一次的时钟中断，生硬，无序。
2、不好实现阻塞系统调用。一个线程使用阻塞系统调用会阻塞全部线程。解决方法：
1）使用非阻塞的系统调用，需要修改操作系统。
2）使用包装器（在系统调用周围进行检查），如果某个调用会阻塞，通知。需要重写部分系统调用库，不高效不优雅。
3.页面故障问题，由于系统不知道是多线程，当一个线程引起页面故障的时候，系统会阻塞整个进程，尽管其他线程是可用的。

				- 线程的切换：
TCB记录一个栈中的esp，切换TCB可以跳至另一个线程的栈；两个线程合作时，需要两个栈，不能合用，两个TCB，再切换PC（通过thread_yield函数）；

					- 如果进程的某个线程进入内核并阻塞，则阻塞了同一进程下的其他线程
					- 相比用户级线程，核心级线程更灵活，不容易阻塞

			- 核心级线程实现
schedule thread

				- 内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核（Kernel，下称内核）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。 每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（MultiThreads Kernel）。

					- 内核态
					- 应用程序使用内核线程的一种高级接口——轻量级进程（Light Weight Process,LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。 这种轻量级进程与内核线程之间1:1的关系称为一对一的线程模型

				- 优点：
1、线程阻塞时不仅可以切换到同一进程内的其他线程，也可以切换到其他进程内的线程。当一个线程阻塞的时候，系统可以选择所有进程中的任一就绪线程执行。而用户级线程只有在进程被剥夺CPU时才能选择其他进程中的线程。 
2、页面故障问题不会引起所有线程都进入阻塞，内核可以选择同一进程下的其他线程。
3、由系统内核将线程分配（通过MMU映射实现）到不同的CPU中，实现多核并行。

					- 缺点：
1、线程的新建、销毁、切换的代价都比较大

				- 线程的切换：
TCB关联内核栈，由用户级线程需要一个栈转为一套栈（用户栈+内核栈）。
用户栈通过INT指令进入内核栈，内核栈通过IRET返回用户栈

					- 五段论:
1、中断入口：通过系统中断INT0x80从用户栈进入内核栈
2、中断处理：可能阻塞引发schedule()
3、继而找到下一个TCB
4、通过TCB完成内核栈切换
5、中断出口：中断返回，再从内核栈进入用户栈。从而完成用户栈的切换。

						- 实现代码
linux用的方法TSS方法，现代操作系统用的更多是
create kernel threads

						  // 某个中断
						  main()
						  {
						  	A();
						  	B();
						  }
						  A(){	fork();}
						  
						  //执行A()，包含了系统调用fork()，fork()进入系统中断入口，由PC（堆栈指针）从用户栈进入内核栈（此时内核栈为空）
						  fork(){
						  	move %eax, _NR_fork
						  	INT 0x80
						  	mov res, %eax
						  }
						  
						  //查系统中断函数表，INT 0x80对应的是:
						  _system_call:
						  	push %ds..%fs
						  	pushl %ds..%fs
						  	pushl %edx...
						  	call sys_fork
						  	pushl %eax  //上述代码将陷入内核栈前的上下文信息先压栈保存 
						  
						  //sys_fork内核通过判断线程是否阻塞/用时间片是否用完，触发栈的切换
						  sys_fork:
						  movl _current, %eax
						  cmpl $0, state(%eax)
						  jne reschedule
						  cmpl $0, counter(%eax)
						  je reschedule
						  ret_frim_sys_call:    //从中断返回
						  
						  //schedule执行调度
						  reshedule:
						  	pushl $ret_from_sys_call
						  	jmp  _schedule
						  
						  //
						  void schedule(void){
						  	next = i;
						  	switch_to(next);}
						  
						  //
						  ret_from_sys_call:
						  	popl %eax  //返回值 popl %ebx
						  	pop %fs ...    //把之前压栈的上下文信息弹出 
						  	iret // 返回到 int 0x80之后执行
						  
						  //切换方法：
						  a、TSS task structure segment 任务结构段切换
						  b、kernel 切换
						  
						  //内嵌汇编，整体作用就是记录原指令的上下文（包括所有寄存器），跳转到新的指令所在的段，载入上下文
						  #define swithch_to(b)
						  { struct {long a ,b;}
						  _asm_{
						  "movw %%dx, %1\n\t"
						  "ljmp %0\n\t"
						  ::"m"(*&_tmp.a),
						  :m:(*&_tmp.b),
						  "d"(_TSS（n）}

					- 上行调用：

						- 运行时系统：
指一种把半编译的运行码在目标机器上运行的环境。
						- 保持内核级线程优良特性的前提下改进速度。线程包位于用户空间。
内核给每个进程分配一定数量的虚拟处理器，通常为一，进程可以自己申请，也可以在用完之后返回。运行时系统将线程部署到虚拟处理器上。
当内核知道一个线程被阻塞之后，内核通知进程运行时系统，并在堆栈以参数形式传递有问题的线程编号和所发生事件的一个描述。之后在一个已知地址启动运行时系统，使其重新调度线程。 

在cpu中用户空间为上层，内核为下层，常规调用应该是上层调用下层，下层不应该调用上层，upcall就是指内核调用用户空间。

				- 线程的新建：

					- 实现代码
copy_process

					  ThreadCreate
					  
					  _sys_fork:
					  	push %gs;
					  	pushl %esi
					  	...
					  	pushl %eax
					  	call copy_process  //拷贝整个线程的上下文
					  	addl %20, %esp
					  	rst
					  
					  //
					  copy_process:主要功能
					  
					  1、申请内存空间，在mem_map中寻找0地址，划分出内存空间
					  2、在内存空间中建立TCB
					  3、设置TSS各项属性，创建内核栈，创建用户栈，和父进程共用栈

					- 内核栈和其他线程不同，但用户栈和父进程共用栈

			- 线程的两种实现方式：
用户级线程和核心级线程的区别

				- 
用户线程

    用户线程存在于用户空间，由线程库统一管理，对内核透明（也就是说内核并不知道有用户线程的存在）

    用户线程的创建和销毁均在用户空间由线程库实现，无需内核干预，不需要调用系统调用，也就不会有用户态与内核态相互切换的开销

    用户线程不具有自己的上下文，不能直接参与CPU的竞争，必须关联一个内核线程，由内核线程去竞争CPU资源（操作系统是以内核线程为最基本的单位，分配CPU资源的）
				- 
内核线程

    内核线程存在于内核空间，由操作系统管理。

    内核线程的创建和销毁都是通过系统调用来完成的

    内核线程是操作系统分配CPU资源的最小单位（也就是说内核线程是直接参与CPU竞争的）=> 每次调度器选择一个内核级线程，为其分配CPU的使用权（比如说可以是时间片）

			- 混合实现

				- 使用内核级线程，然后将用户级线程与某些或者全部内核线程进行多路复用。

    多对一：许多用户级线程映射到同一个内核线程。效率高，但一个线程执行了阻塞系统调用，整个进程将会阻塞。线程管理由线程库在用户空间管理。内核一次只能调用一个线程，没有提高并行性。
    一对一：并行性好，缺点开销大，每一个用户线程就要建立一个内核进程。限制线程数。
    多对多：多路复用。不限制线程数，并行性好。

内核只识别内核级线程，而内核级线程操作用户级线程集合。

			- 在cpu中用户空间为上层，内核为下层，常规调用应该是上层调用下层，下层不应该调用上层，upcall就是指内核调用用户空间。

		- 并发：
多个进程间的隔离

			- 指令序列的分离
			- 存储上的分离

				- 一个程序访问一块内存时要给其上锁，阻断其他程序对该内存块的访问
				- 基本实现思想：
使用地址映射表，分离内存使用的空间

					- 每一个进程有自己单独的映射表，每个映射表之间使用的物理内存块是分离的

		- 并发：
多个进程间的同步与合作

			- 进程间如何通信

				- 两种基本模式：
    共享内存（速度快）
    消息传递

			- 进程通信如何实现同步与合作
几种同步机制

				- 共享内存
隐式通信 显式同步

					- 适用条件：公共内存的一个或多个cpu中适用公共内存
					- 竞争条件出现：
以打印机队列为例，公共内存的一个或多个cpu上的互斥问题

避免竞争条件的核心思想——互斥：
确保一个进程正在使用一个共享变量或者文件的时候，其他进程不能做同样的操作。

						- 临界区：代码中访问共享内存区域的程序段
						- 临界区保护：
共同修改信号量，可能使得信号量的取值和当前实际状态不同。或者说竞争条件(race condition)引起的语义错误。
执行读写信号量的代码段就是临界区(critical section)。为了形成保护效果，要在临界区的前后设计进入区和退出区的代码，形成一种上锁的效果。上锁，这种在进程层面不可继续分解的操作称为原子操作。
						- 解决临界区问题的基本原则：
互斥原则（mutual exclusion）

好的临界区代码：
有空快进：临界区空闲，应尽快使一进程进入临界区
有限等待：从进程发出进入请求到允许进入，不应无限等待
不对cpu的速度和数量有任何假设。
						- 解决方案

							- 1。某些共享数据结构，如信号量，可以放在内核中，只能由系统调用访问
2。让进程之间共享部分地址空间
							- 硬件解法：关中断

								- INTR寄存器，用于实现系统中断
								- 问题：
系统中断关闭后，进程不能被调度，不能执行进程切换
把屏蔽中断的的权利交给用户不安全，也许中断不再打开，系统死机。
但是在多核（多CPU）的情况下，不能中断所有CPU

							- 硬件原子指令法

								- 原子操作：
单一的，不可分割的一系列操作，要么都执行，要么都不执行

								  boolean TestAndSet(boolean &x)
								  {
								  	boolean rv = x;
								  	x = true;
								  	return rv;
								  }

								- 测试并加锁指令，需要硬件支持。执行该指令会锁住内存总线，以至于只有执行该指令的进程可以对共享内存做出修改。
“TSL指令”就是原子性地完成“检查-占锁”的动作。
XCHG指令:原子性的交换两个位置的内容，用来设置锁。
两个指令都能确保只有一个cpu对共享内存进行操作。

									- 问题：忙等待
									- 解决方法：使用通信原语：sleep，wakeup，无法进入临界区的时候将会阻塞而不是忙等待。 

							- 软件解法：轮换+标记

								- 代码实现：
轮换法
在进入临界区之前，用if检查一个bool值，条件不满足就“忙等”。bool值得叫“锁变量”。

								  //进程P0
								  while( turn != 0);  //空转
								  [临界区代码]
								  turn = 1;
								  [剩余区代码]
								  
								  //进程P1
								  while( turn != 1);  //空转
								  [临界区代码]
								  turn 0;
								  [剩余区代码]

									- 问题：满足互斥，不满足有空快进
用于忙等待busy waiting 的锁，自旋锁 spin lock
一个进程比另一个进程速度慢了很多的情况下，会导致快的进程空循环等待，CPU空转，仅在等待时间极短的情况下才可使用

								- 代码实现：
peterson算法

									- 问题：满足互斥，不满足有空快进
忙等待

								- 代码实现：
标记法

									- 问题：满足互斥，不满足有限等待
无法进入临界区的时候将会阻塞而不是忙等待
									- 互斥量/互斥锁，信号量的简化版本
广义上讲可以值所有实现互斥作用的同步机制。狭义上讲指的就是mutex这种特定的二元锁{0，1}机制。

								- 两个进程临界区的代码实现：
非对称标记，轮换+标记

								  //进程P0
								  flag[0] = true;
								  turn = 1;
								  while(flag[1] && turn == 1);
								  [临界区代码]
								  flag[0] = false;
								  [剩余区代码]
								  
								  //进程P1
								  flag[1] = true;
								  turn = 0;
								  while(flag[0] && turn == 0);
								  [临界区代码]
								  flag[1] = false;
								  [剩余区代码]

									- 信号量用一个整型变量表示
累计唤醒次数，根据信号量来唤醒另一个进程，或让另一个进程继续等待

									  struct semaphore{
									  	int value; //记录资源个数
									  	PCB *queue；
									  	//记录等待在该信号量上的进程
									  }
									  P(semaphore s)；  //消费资源
									  V(semaphore s);  //产生资源
									  
									  P(semaphore s){  //信号量+1
									  	s.value--;
									  	if(s.value < 0){
									  		sleep(s.queue);
									  }
									  
									  V(semaphore s){  //信号量-1
									  	s.value++;
									  	if(s.value <= 0){
									  		wakeup(s.queue);
									  }

									- 多个进程临界区的代码实现：
面包店算法
每个进程都获得序号，序号最小的进入临界区

								- 管程

									- 有些编程语言实现了“管程”的特性，从编译器的层面保证了临界区的互斥，比如Java的synchronized关键字。
									- 是一种语言概念，c语言不支持，java支持，只要将synchronized加入到方法申明中即可

重要特性：任意时刻管程中只能有一个活跃进程

管程是编程语言的一部分，由编译器来负责进入管程的互斥。编程人员无需知道编译器是怎样实现互斥的。一般是使用一个互斥量或二元信号量。
以及使用条件变量来使进程在无法运行的时候被阻塞。

				- 消息传递
显式通信 隐式同步

					- 适用条件：分布式系统具有多个cpu，而且每个cpu拥有自己的私有内存，他们之间通过局域网链接

						- 使用两条原语：send，receive
						- 问题：
    不可靠的消息传递以及重复发送时的成功通信
    进程命名的二义性问题
    身份认证问题
    性能问题

					- 如何可靠传递

						- 解决方案

							- 对消息进行编址

								- A方法
为每个进程分配一个唯一的地址，让消息按进程的地址编址
								- B方法
引入新的数据结构——信箱。

									- 对于信箱的使用：
    1。信箱创建时确定消息的数量。使用时send和receive调用的是信箱的地址。对满的信箱发消息的进程将会被挂起。
    2。彻底取消缓冲。如果send在receive之前执行，则发送进程被阻塞，直到receive执行，消息直接从发送者复制到接受者，不用任何缓冲。
    反过来也是一样。实现容易，但灵活性不行。因为发送者和接受者必须一步步紧紧相接。

				- 屏障

					- 适用条件：用于进程组。在应用中划分了阶段，规定除非所有进程都就绪准备着手下一阶段，否则任何进程都不能进入下一阶段。可以通过在每个阶段的结尾设置屏障来实现。比如矩阵运算，需要全部运算完一轮，才能进入下一轮。

				- Inter-ProcessCommunication IPC问题

					- 哲学家就餐问题
					- 读者写者问题

			- 进程如何解决同步异常

				- 死锁的成因：
信号量方法如果处理不当，可能进入多个进程互相等待对方持有资源而造成无法执行的情况。
资源互斥使用，一旦其他进程无法使用。

					- 举例

						- 正常情况：

						  正常情况：
						  producer(item){
						  p(empty);  // empty 0--1，进入阻塞，等待consumer()执行，解除阻塞
						  p(mutex);  //
						  [读入in，将item写入到in的位置上]
						  v(mutex);
						  v(full)；
						  
						  consumer(){
						  p(full);  //size - 1
						  p(mutex); //
						  [读入out，从out位置读到item，打印item]
						  v(mutex);
						  v(empty);  //empty -1--0，解除了producer()的阻塞

						- 死锁情况：

						  producer(item){
						  p(mutex);  // mutex 1--0
						  p(empty);  // empty 0--1，进入阻塞，等待consumer()执行，解除阻塞
						  [读入in，将item写入到in的位置上]
						  v(mutex);
						  v(full)；
						  
						  consumer(){
						  p(mutex); // mutex 0 -- -1进入阻塞，等待producer()执行解除阻塞
						  p(full);  //size - 1
						  [读入out，从out位置读到item，打印item]
						  v(mutex);
						  v(empty);  //empty -1--0，解除了producer()的阻塞

					- 形成的必要条件

						- 1、互斥使用
2、不可抢占，资源一旦占有只能占有者自行离开
3、请求和保持，进程占有资源的同时还请求其他资源
4、循环等待，资源分配图中形成了循环

				- 死锁的处理

					- 死锁预防
破坏形成的条件

						- A、一次性申请号所有需要的资源，不会占有资源在去申请其他资源。但是需要预先计算，编程困难，而且资源分配后不会立刻开始使用。
						- B、对资源类型排序，资源申请按序申请，仍然有资源浪费

					- 死锁避免
检测资源请求，如果死锁已形成，拒绝请求

						- 使用银行家算法，判断是否存在一个可完成的执行序列
找出安全序列
每次都要检测，代价较大 O(m n^2)
A、使用银行家算法找出可行路径
B、假设可以给出资源，检测是否造成死锁

						  Dijkstra

					- 死锁检测+恢复
检测到死锁出现时，进程回滚roll back，让出资源

						- 效率较高，但是实现复杂。roll back操作比较复杂

					- 死锁忽略
忽略死锁的出现

						- linux和windows较常使用。死锁出现可通过系统重启来解决。

		- 并发：
多个线程/进程之间的调度

			- 缘由：
单次IO操作耗时是单次CPU计算耗时的10^6倍

				- 交替执行能够提高CPU利用率
				-  使用cpu——计算
 一个进程等待外部设备完成工作而阻塞——I/O活动
进程分类：
    计算密集型——将大部分时间放在计算上。
    I/O密集型——将大部分时间放在等待I/O上
    随着cpu越来越快，更多的进程倾向为I/O密集型，其结果为I/O密集型的进程调度处理更为重要。以便发出磁盘请求并保持磁盘运转。

			- 进程交替的三个部分：
队列操作+调度+切换

				- 操作系统如何实现多个进程？（队列操作的实现）：

					- 由每个程序的PCB（process control block）完成
多个程序的PCB组成 就绪队列、磁盘等待队列
就绪队列：等待执行的进程
磁盘等待队列：等待某事件完成的进程
					- 进程状态图（状态之间相互转化）：
新建态——就绪态——运行态——终止态

就绪态——运行态——阻塞态——就绪态

				- 操作系统如何选择切换进程/线程？（调度）

					- 长期调度：进程被提交到硬盘的缓冲池中，由长期调度程序选择调入内存。
短期调度（cpu调度）：从内存中准备执行的进程中选择执行。
中期调度（分时系统中）：将进程从内存中移出，减少多道程序的道数。称为交换。
					- 评价标准

						- 指标：
周转时间=等待时间+执行时间
带权周转时间=周转时间/执行时间

					- 进程调度

						- 何时执行调度

							-     进程创建后，父子进程的执行顺序
    进程退出时，选择一个进程运行
    进程阻塞的时候。
    I/O中断的时候，是否让等待该I/O的进程执行

						- 调度机制和调度策略分离

							-  可以利用时钟中断来做出调度决策，根据如何处理时钟中断可分为非抢占式算法（忽略时钟中断，运行直到进程放弃cpu）和抢占式调度算法（固定时段挂起进程）

						- 调度算法的目标和设计

							- 所有系统

								- 目标
公平——给每个进程公平的CPU份额
    策略强制执行——调度程序拥有强制执行权利
    平衡——保持系统的所有部分忙碌，CPU密集型+I/O密集型

							- 批处理系统

								-     吞吐量——每小时最大作业数
    周转时间——从提交时刻到完成时刻的统计平均时间
    CPU利用率——保持CPU始终忙碌
								- FCFS（先来先服务）：
按照请求CPU的顺序使用CPU。
缺点：1.周转时间与响应时间无法保证 2。对短作业不利

SJF（最短作业优先）不可抢占：
要求运行时间可以预知，最短的作业放在最前。只有在所有进程可同时运行的时候才是最优化的。平均等待时间最短，平均周转时间最短。

最短剩余时间优先，可抢占：
最短作业优先的可抢占版本。
缺点：1。对长作业不利

最高响应比（HRN）
先来先服务和最短作业优先的综合平衡。
R=(W+T)/T W:等待时间 T:执行时间

							- 交互式系统

								-     响应时间——快速响应要求
    均衡性——满足用户的期望，调整调度顺序
								- 轮转调度：
每个进程被分配一个时间段，称之为时间片。时间片结束的时候，剥夺CPU分配给其他进程。如果时间片结束之前进程阻塞或结束，立刻切换进程。实现方式：维护一张可运行进程的列表。时间片太短会导致太多进程切换，降低了CPU的效率；太长则可能造成对短交互请求的响应时间太长。20~50ms通常是比较合适的折中。平均周转时间长。

优先级调度
每个进程被分配不同的优先级，优先级高的先运行。为了防止高优先级的进程一直运行，在每一个时钟中断的时候降低优先级，如果比次高优先级进程低，则切换。不及时调整老化将会出现饥饿。对于I/O密集型的进程，为了让它获得高优先级，以保持I/O设备活跃，将其优先级设置为上一个时间片使用CPU时间所占时间片比例的倒数，使用CPU时间越短，优先级越高。

多级队列：
为CPU密集型的进程分配较长的时间片比频繁分配较短的时间片效率要高。所以设立优先级类，优先级越低，每次分配的时间片个数就多。（I/O密集型优先级别高）允许改变优先级：多级反馈队列调度

最短进程优先
等待命令，执行命令，把每一条指令的执行看做是一个独立“”作业“”，运行最短作业来使响应时间最短。实现方式：老化—>通过当前测量值和先前估计值进行加权平均而得到下一个估计值。T0->1/2T0+1/2T1->1/4T0+1/4T1+1/2T2

									- 保证调度
向用户作出明确的保证，然后实现。将进程自创建以来的时间除以进程数。计算出真正获得的CPU时间和应得的CPU时间之比。如0.5说明只获得了应有的时间的一半。

彩票调度
向进程提供系统资源的彩票，需要做出决策的时候，就随机抽出一张彩票，拥有该彩票的进程获得资源。按照进程的重要程度给予进程不同的彩票数量。协作进程之间彩票可以交换。
公平分享调度

按照用户数量平均分配资源。

							- 实时系统 

								-  满足截止时间——避免丢失数据
可预测性——在多媒体系统中避免品质降低
								- 在实时系统中，迟到的正确应答比没有应答更加糟糕

					- 线程调度

						- 许多适用进程调度的方法也适用线程调度
						- 用户级线程

内核不知道有线程的存在，内核给予进程时间片，进程中的线程调度程序选取线程运行，但是因为多道线程中没有时间中断，该线程会一直执行直到结束。但是该线程的不合群行为不会影响到其他的进程
						- 内核级线程

内核选择一个线程运行，且不关心它是属于哪一个进程。
						- 区别

二者区别在于性能，用户级的线程切换需要少量的机器指令，内核级线程需要完整的上下文切换，但是一旦线程阻塞在I/O上时，不需要像用户级线程那样挂起整个进程。
用户级线程能使用专为应用程序定制的线程调度程序，能将并行度最大化。而内核从来不了解每个线程的作用。

				- 操作系统如何实现不同进程间的切换？（切换操作的实现）

					- 1、记录当前执行信息（地址、操作数）
2、修改寄存器PC，切换到其他进程
3、切换指令流，CPU状态的互相覆盖，操作寄存器完成切换
4、切换资源，映射表切换

						- PCB（进程控制块）

						  1.进程控制块的作用　　
						  　 进程控制块是进程实体的一部分，是操作系统中最重要的记录型数据结构。PCB中记录了操作系统所需要的、用于描述进程情况及控制进程运行所需要的全部信息。进程控制块的作用，是使一个在多道程序环境下不能独立进行的程序（含数据），成为一个能独立运行的基本单位，一个能与其他进程并发执行的进程。或者说，操作系统是根据PCB来对并发执行的进程进行控制和管理。　　
						  　 2.进程控制块中的内容　　
						  　 在进程控制块中，主要包括4个方面内容。　　
						  　 （1）进程标识符信息。进程标识符用于惟一地标识一个进程。一个进程，通常有以下两个标识符：外部标识符，内部标识符。
						  　 （2）处理机状态信息。处理机状态信息主要是由处理机各种寄存器中的内容所组成。
						  　 （3）进程一调度信息。在PCB中还存放了一些与进程调度和进程对换有关的信息，包括：进程状态、进程优先级、进程调度所需要的其他信息、事件。
						  　 （4）进程控制信息。进程控制信息包括：程序和数据的地址、进程同步和通信机制、资源清单、链接指针。　　
						  　 3.PCB的组织方式　　
						  　 在一个系统中，通常可拥有数十个、数百个乃至数千个PCB，为能对它们进行有效管理，应该用适当的方式将它们组织起来，目前，常见的组织方式有两种，链接方式和索引方式。

- 内存管理

	- 工作原理

		- 指令存放在内存中
计算机取指执行

			- 程序如何进入到内存中？

				- entry放在实际物理内存的0地址，从0地址跳转到40地址
（main程序的入口）

		- MMU memory management unit
存储器管理单元

	- 非连续内存分配

		- 重定位：逻辑地址转换为物理地址，也就是修改程序中的相对地址为绝对地址

			- 编译时重定位

				- 较快，只能放在内存的固定位置。

			- 载入时重定位

				- 更加灵活，但更慢，一旦载入内存，不可移动。

			- 运行时重定位

				- 满足交换（swap）的要求（内存碎片整理的一种）
将进程从内存移出保存在磁盘，往后再从磁盘重新载入。
				- 分配空闲内存给程序，并将内存地址赋给程序的PCB，程序中每条指令通过都从逻辑地址+PCB给出的基址算出物理地址。

		- 内存分段 memory and segmentation：
程序载入时，并非是将整个程序一次整体载入内存。内存的存放不是完全连续的，程序的各段是分别放入内存。内存可以动态存放，提高了内存使用效率。

			- GDT表，操作系统使用的进程段表

				- jmp 0,8

			- LDT，某个进程使用的进程段表
记录了一个进程 code、data所在的地址位置

		- 在内存中如何找到空闲分区？
内存分区 memory partition

			- 如何将空闲分区读入？
			- 如何使用LDT完成和PCB的映射关系？
			- 固定分区和可变分区

				- 固定分区：
系统将内存等分成一定长度的分区
				- 可变分区的管理过程：
空闲分区表+已分配分区表
空间分区表包括 起始地址+长度

					- 请求分配 操作
首先适配，均匀随机，查到最近的可用内存
最佳适配，找出和请求分配长度接近的内存部分
最差适配，找出较大的块
					- 内存碎片可能较小，如果请求一块很大的内存，没有空闲分区可满足长度。采用内存紧缩的方法合并内存块，过程较为耗时。

		- 内存分页 memory paging：

			- mem_map将每4k划分为1个页。
分配中以内存页为基本单位分配，向上取整。最多浪费1页。不需要内存紧缩操作。
			- 使用页表（寄存器 页线性地址cr3）记录了页号，页框号，保护（R/W），有效
由内存管理单元MMU快速计算分页位置
PCB中记录了页表指针

				- 页小，页表巨大的问题、连续存储的话内存耗费大。页表只存放用到的逻辑页，内存耗费小，但是即使采用顺序查找、二分查找的方法查找指定页，对于4个G大小的页表 每次查找操作，最快Log(2^20) = 20 次
不可行
				- 既要连续存储页，又要减少页表占用的内存
				- 多级页表
页目录表+页表

					- 提供了空间效率，保证连续且节省存储。多级页表存储在磁盘，不占内存。
					- 访存次数增加。对于64位系统，可能需要4~5次访存，时间变为数倍

				- 快表
相连快速存储TLB

					- 利用的是程序的局部性原理
					- 在CPU与内存访问之间加一层TLB，TLB是一组寄存器，用来存放最近使用过的页对应的页框号；这样如果CPU需要访问某一页首先在TLB里面找，如果TLB里面有就不用访问内存了，因为TLB是寄存器，cpu访问寄存器的速度远大于对内存的访问速度。这样就可以提升时间性能了。
					- 如果命中，效率极高，如果没命中，要再采用多级页表的方法。命中率要高，总体耗时才会降低。

	- 地址空间-虚拟内存

		- 使得以用户程序的视角看起来内存是分段的，以物理内存的视角看起来又是分页的，这种机制就是虚拟内存
		- 工作机制：
逻辑地址究竟是如何变成物理地址的呢？
逻辑地址是段号+偏移（CS：IP），得到虚拟地址
在页表中查找虚拟地址是页号+偏移。根据页号在页表中找到对应的页框号，再加上偏移得到最后的物理地址。
		- 设计实现

			- 第一步：在虚拟内存上分配段（用户栈段|用户代码段|用户数据段|操作系统段）；使用内存分区方法在虚拟内存上找到空闲的段
第二步：将用户程序映射到虚拟内存，建立段表。
第三步：虚拟内存段又打散，分配页，建立页表。分配页并不是在内存里面查找空闲页，而是采用。

				- 代码实现
fork()

				  在Linux/kernel/fork.c
				  int copy_process(int nr, long ebp...)
				  {
				  	………………
				  	copy_mem(nr,p);
				  	………………
				  }
				  
				  int copy_mem(int nr, task_struct *p)
				  {
				  	unsigned long new_data_base;
				  	new_data_base = nr*0x4000000;		// nr * 64M
				  	set_base(p_>ldt[1], new_data_base);		// 代码段
				  	set_base(p->ldt[2], new_data_base);		// 数据段
				  	………………
				  }

				- 第一步：分配内存
给进程在虚拟内存上分配一块64M的内存块。比如第0个进程内存区域就是0 ~ 64M，第一个进程64~128M，依次类推，互不重叠。然后将pcb的ldt[1]和ldt[2]都指向这块内存。ldt[1]和ldt[2]指的是数据段和代码段
				- 第三步：建立页表
在父进程中建立子进程，两者公用同一块内存，将32位地址映射到页表上；
将父进程的from_page_table赋值给子进程的to_page_table，并且将对应的页设置为只读。这也是前面说的为什么不用为子进程找空闲页，因为子进程用的就是父进程的内存。为什么要设置为只读属性？两个进程共享同一块内存，如果都是读，没有任何问题，但是如何要写呢？那么就出问题了；
				- 计算机将查表的操作交给硬件来完成，只要从用户程序那里得到CS：ip，硬件会自动得到该逻辑地址对应的物理地址的，这个硬件就是MMU。

			- 内存换入-内存换出
swap in - swap out
实现大内存

				- 换入：使用虚拟内存时，请求调页后，数据从磁盘读取到实际物理内存中，同时建立页面映射。

					- 缺页中断 page fault：
请求调页，若在虚拟地址中查找页号，MMU查找发现该页面为空，系统中断，将页面从磁盘中调入到物理内存，建立页表和页面的映射。

				- 换出：内存满的时候，缺页的时候，选择内存换出的策略

					- FIFO

						- 缺页时替换出最开始的一页
没有什么优化

					- MIN
理想的最优方案

						- 将使用时间距离现时最远的页替换出去

							- 无法实现，因为无法实现知道进程后续将要使用的页面

					- LRU

						- 根据程序的空间局部性原理
						- A方法：
使用时间戳来记录每页的访问时间，每次选择替换时间戳最早的页面。该方法需要维护一个全局时钟，再使用指针找到时间戳最小值，实现代价较大。
						- B方法：
使用固定大小的页码栈来记录最近使用的若干页面，每次选择替换栈底的页面。需要维护一个页码栈，实现代价也较大。
						- C方法：
clock方法。将页面组织位循环队列，每页记录一个引用位{0，1}，一个内存页被访问时，内存页置为1。缺页时，循环访问所有页，将引用位1的置为0，将引用位0的替换。这种方法在缺页情况发生频率低的时候，退化为FIFO

							- 再加一个指针，定时清除引用位为0；可以通过系统的时钟中断来实现。

			- 每个进程分配多少页框？（帧frame）

				- 分配过多，请求调页的情况少，但可容纳的进程少
				- 分配过少，可容纳的进程多，但进程缺页的频率增加。当缺页率增大到一定程度，进程就会等待调页完成，倒置CPU利用率降低。

### 文件view

- 终端设备管理

	- 整体三步原理

		- 1、CPU取址执行通过out指令向外设发送指令
2、将外设的寄存器操作、命令格式和语义等通过文件抽象形成统一文件视图进行解释
3、外设执行命令后返回（显卡显示图像/键盘读取数据到内存），CPU中断处理

			- 操作系统为设备提供统一的设备接口（open() read() write() close），根据设备文件（内有设备属性数据）进行解释，找到控制器地址、内容格式要求等，转为设备命令，通过设备控制器操作外设。

	- 设备文件-设备驱动

		- I/O设备

			- 键盘

				- 举例：键盘输入

			- 显示器

				- 举例：显示器输出

				  在linux/fs/read_write.c中
				  int sys_write(unsigned in fd, char *buf, int count){
				  	struct file* file;
				  	file = current->filp[fd];
				  	inode = file->f_inode;  //inode就是设备属性信息
				  
				  int copy_process(...){
				  }
				  
				  int sys_open(){
				  	[从inode中打开]
				  }

			- 磁盘

- 磁盘管理
raw disks

	- 文件-文件系统
	- 生磁盘的使用

*XMind: ZEN - Trial Version*