# 3.3.2 分布式系统 （distributed system）

参考：https://waylau.gitbooks.io/distributed-java/docs/basic.html

参考：《分布式系统概念和设计》

## 什么是分布式系统？

### 分布式系统为何产生？

- 初衷：任务需求过大，单机系统无法解决时，可以提高单机系统的性能，或者扩展系统，利用集群多机的能力。分布式系统就是试图解决单机系统无法解决的计算和存储问题。

### 分布式系统的定义和模型？

- 定义

  - 具体如何仍然需要长期的观察、总结和实践

  - 《分布式系统原理与范型》一书的定义：
    分布式系统是若干独立计算机的集合，这些计算机对于用户来说就像是单个相关系统。
    硬件独立：计算机机器本身是独立的
    软件统一：对于用户来说，他们就像是跟单个系统打交道

  	- 分布式系统的系统特性：
  内聚性：子系统之间仅仅通过网络连接交换数据，子系统内部独立完成大量计算机任务。
  透明性：用户和应用程序交互时，不会察觉哪些部分正在替换或者维修，也不会感知到新部分的加入。

  - 维基百科对“分布式系统”的宏观定义：

    分布式系统是一种其组件位于不同的联网计算机上的系统，然后通过互相传递消息来进行通信和协调。为了达到共同的目标，这些组件会相互作用。
    
  - 其他定义：分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是利用更多的机器，处理更多的数据。

- 分布式系统模型

  - **物理模型**
  - **体系结构模型**
    - 通信实体（进程 == 对象 / 组件 / 服务） + 通信范型（基于IPC socket的远程方法调用 RMI /  基于IPC socket的远程过程调用 RPC / 基于中间件的间接通信（组通信( 发布订阅系统 / 消息队列 ) | 分布式共享内存 DSM））  + 通信中实体的关系（从角色和责任看，分为客户端/服务器 和 P2P 两种类型）
    - 体系结构模式：应用/服务--中间件--平台（操作系统--计算机硬件和网络硬件）
      - 两层解决方案，在WebAPP开发上体现为 model1 + model2
      - 三层解决方案，在WebAPP开发上体现为 MVC
      - 代理模式
      - 等等
  - **基础模型。分布式系统需要解决的共性问题**
    - 交互模型
      - 受限进程之间通信不可靠的问题、进而受限进程之间没有同一的时钟，
      - 进程难以同步的问题
    - 故障模型，如何应对系统内部交互出错的情况？
      - 遗漏故障：进程遗漏故障和网络遗漏故障
      - 随机故障
      - 时序故障（同步类型的分布式系统特有的）
      - 以上几种故障的检测手段和修复方法
    - 安全模型，如何防范系统外部的攻击？
      - 保护对象，保护进程和进程交互过程（也就是通信过程）
      - 威胁
        - 对进程的威胁
          - 客户机
          - 服务器
            - 比如洪泛攻击，要采用拒绝服务的方法解决
            - 比如移动代码，典型的就是SQL注入
        - 对通信通道的威胁
          - 中间人攻击，伪造消息。HTTP-HTTPS
      - 安全手段
        - 密码学，加密与解密
          - 权限认证
        - 安全信道

### 分布式系统的类别

- 数据存储，计算，文件系统，邮件系统，分类帐，应用程序

### 性能指标：
吞吐量、并发数、响应延迟

### 非性能特征：

可靠性、可拓展性、一致性，每一方面都要通过多种技术手段来改进

- 可用性

	- 系统在面对各种异常时可以正确提供服务的能力。分布式系统某些节点故障，不影响整体的可用性。好的分布式系统，系统停服务的时间与正常服务的时间的比例应是尽量低的。

- 可拓展性

	- 分布式系统通过扩展集群机器规模提高系统性能（吞吐、延迟、并发）、存储容量、计算能力。好的分布式系统总在追求“线性扩展性”，也就是使得系统的某一指标可以随着集群中的机器数量线性增长。

- 一致性

	- 分布式系统为了提高可用性，总是不可避免的使用副本的机制，从而引发副本一致性的问题。一致性衡量了系统应对此问题的能力。越是强的一致的性模型，对于用户使用来说使用起来越简单，数据更新后可以立刻读到最新的修改。

## 分布式系统的模型

### 分布式系统的交互模型（实现进程之间的通信和同步）

- 解决分布式算法的问题。区别于严格顺序执行的单机上的算法，分布式算法的执行步骤并非严格按照顺序。
- 分布式系统的影响进程交互的主要方面：通信信道的性能问题 和 通信延迟带来的计算机时钟问题。这两个问题不明确解决，节点间的同步也就无从谈起。
- 分布式系统进程交互的行为
  - 多播multicast

#### 通信信道的性能。不同节点上的通信实体需要通过消息传递完成任务，怎么保证通信过程是可靠的。解决这个问题的关键是设计可靠的网络协议。

- 不管采用哪种通信范型（RMI | RPC | 间接通信），通信时间都不能保证（网络延迟和网络带宽会变化）
  - communication channel 的固有缺陷
    - 延迟（延迟包括单机发送/接受消息的延迟 + 消息进入网络的延迟 + 消息在网络中传输的延迟 + 消息在路由系统中排队的延迟等等）
    - 带宽，网络拥塞情况可能不断变化
    - 抖动 jitter

#### 时间和事件的模型：计算机时钟和时序事件。计算机不同节点上的时钟不能完全同步一致，怎么确定事件的先后顺序。解决这个问题的关键是**逻辑事件模型**。

- 产生原因
  - 每个单机内置时钟不同
  - 单机上的进程 Local clock of different processes show different time values  
  - Clocks drift from perfect times at different rates  
- 分布式系统和物理时钟的同步。1、系统和外部UTC事件源的外部同步 2、系统内各线程之间的内部同步
  - 外部同步，两个进程之间如何同步时间？比如客户端和服务器。
    - Tc = (Ts + (min + max)/2), skew(client,server) ≤ (max – min)/2  。最优方法。
  - 内部同步，同步时钟的算法
    - Cristian Algorithm 用于企业内网
      - 有时钟服务器和外界时钟源进行外部同步。然后内部其他客户端和时钟服务器同步。
      - Tc = Ts + (Tround / 2) ， skew ≤ (Tround / 2) – min (min is minimum one way network delay)  
      - 缺点：中心化的时钟服务器如果故障，整个系统时间都不准。
    - Berkeley Algorithm 用于企业内网
      - 由一个服务器轮循其他节点，统计所有节点时间取平均值，再返回offset给所有节点
    -  Network Time Protocol 用于因特网整体时间同步，比较复杂
      - 对称模式 
- 逻辑时间和逻辑时钟
  - 对于单一进程，推理时间发生的逻辑顺序较为简单。eij is the jth event of the ith process.
    - history(pi) = hi = < ei0, ei1, ei1, …. eim >  
    - happen before先行发生 Happened-before (HB)  
      - 单一进程内 If ∃ pi , e →i e’ then e → e’.
      - 多进程之间，For any message m, send(m) → receive(m)
      - 传递性 If e → e’ and e’ → e” then e → e  
  - 但由于在一个分布式系统中不能完美地同步时钟，所以不能在物理时间上确定event发生的顺序，只能从逻辑上推定。能够从逻辑上推定event发生顺序，才能协调进程对共享资源访问的顺序，进行进程同步。![事件时钟](C:\Users\Jinzhen\Documents\GitHub\CSmarch\jpg\3 计算机系统\事件时钟.png)
    - lamport logic clock  逻辑时钟；缺点，从L(e) < L(e')，不能推出 e -> e'
    - **vector logic clock 向量逻辑时钟**； 克服了lamport的缺点，但相比lamport占用存储较多，信息的有效载荷和进程数成正比。
    - How to compare timestamps across different processes?
      • Physical timestamp: requires clock synchronization.
      • Google’s Spanner Distributed Database uses “TrueTime”.
      • Lamport’s timestamps: cannot fully differentiate between causal and concurrent ordering of events.
      • Oracle uses “System Change Numbers” based on Lamport’s clock.
      • Vector timestamps: larger message sizes.
      • Amazon’s DynamoDB uses vector clocks.  
- 全局状态和一致割集。全局性时钟，
  - State of a process (or a channel) gets transformed when an event occurs. 3 types of events: local computation, sending a message, receiving a message.  
  - Useful to capture a global snapshot of the system:
    • Checkpointing the system state. //查看分布式系统全局状态
    • Reasoning about unreferenced objects (for garbage collection).//查看对象引用关系
    • Deadlock detection.//死锁检测
    • Distributed debugging  //分布式系统的调试
  - 使用一些算法记录下所有进程的状态的集合
    - Chandy Lamport Algorithm 算法是一个采用分布式快照算法来解决记录分布式全局状态一致的算法。[这个算法的核心，就是创造出一个maker来记录整个分布式链的状态，当链上的节点出现异常需要恢复的时候就根据当前状态找到之前的maker，然后重新计算，保证分布式状态一致。](https://www.cnblogs.com/yuanyifei1/p/10360465.html)，Apache Flink基于此算法改进。关键要理解 **不一致的全局状态**和 **一致的全局状态**。一致的全局状态snapshot之间可以形成一个网络，网络中的每一条快照组成的路径都是线性一致性的。
    - 基于全局状态snapshot之间有可达路径，可以用来作为system properties的分析（global state predicates）。推测的规则图示见PPT
      - Stable = once true, stays true forever afterwards  。
      - Liveness = guarantee that something good will happen, eventually 。避免死锁、活锁
      - Safety = guarantee that something bad will never happen.  

- 推论：分布式系统只能做成异步式的，如果是同步的，需要
  - Known upper and lower bounds on time taken by each step in a process.
  - Known bounds on message passing delays.
  - Known bounds on clock drift rates.  

#### 节点间的通信模型，Message-based distributed systems  。逻辑事件模型提供了一种在分布式系统中依靠message推定事件发生逻辑顺序的模型，但没有解决节点间靠什么方法来传递消息的问题，也没有解决如何保证从接收消息顺序中反推消息发出顺序的问题。每一种通信范型都离不开这两个问题的解决。（重点关注组播中如何解决第二个问题的）

![通信实体和通信范型](C:\Users\Jinzhen\Documents\GitHub\CSmarch\jpg\3 计算机系统\通信实体和通信范型.png)

- 通信实体（进程 == 对象 / 组件 / 服务） + 通信范型（就具体实现和通信实体分类，基于IPC socket的通信实体为对象的远程方法调用 RMI /  基于IPC socket的通信实体为服务的远程过程调用 RPC / 通信实体为中间件的间接通信（组通信multicast( 发布订阅系统 / 消息队列 ) | 分布式共享内存 DSM））  + 通信中实体的关系（从角色和责任看，分为客户端/服务器 和 P2P 两种类型）
  - Communication modes **通信范型**
    - 进程间通信
      - Socket-ServerSocket
    - 远程调用
      - 请求-应答
      - RPC(Remote Procedure Call) 远程过程调用
      - RMI(Remote Method Invocatioin) 远程方法调用，分布式对象
    - 间接通信
      - Unicast. Messages are sent from exactly one process to one process.
      - Broadcast. Messages are sent from exactly one process to all processes on the network.
      - **组通信Multicast. Messages broadcast within a group of processes. A multicast message is sent from any one process to the group of processes on the network.**  
        - Distributed storage
          • Write to an object are multicast across replica servers.
          • Membership information (e.g., heartbeats) is multicast across all servers in cluster.
        -  Online scoreboards (ESPN, French Open, FIFA World Cup)
          • Multicast to group of clients interested in the scores.
        -  Stock Exchanges
          • Group is the set of broker computers  
      - pub/sub
      - MQ
      - 元组空间
      - 分布式共享内存 DSM

##### 分布式系统中的进程间通信

单机系统中，进程间通信有 消息传递 和 共享内存 两大类方法。在Linux系统中，消息传递又有管道（匿名管道、有名管道）、消息队列两种，共享内存则有共享内存地址一种。

分布式系统中，进程间通信依靠网络。

- 外部数据表示和编码
  - Java对象序列化和可扩展标记语言
  - 远程对象引用
- 一对一的进程间的通信
  - 互联网协议比如TCP和UDP的API 和 对API的抽象 Socket
- 一对多的进程间的通信，组播通信multicast ----> 组通信 group communication
  - 组播，多个进程之间的消息传递的通信。多节点通信的关键问题是，消息到达的顺序和消息发出的顺序不一致，那么如何判断。解决这个问题的关键就是实现组播的有序性的几种算法（ISIS等等）。重点是实现组播的Gossip算法，实现消息的传播。
  - 组播 Multicast 可靠性和排序问题
    - 基本组播 basic multicast，use a reliable one-to-one send (unicast) operation:  
    - 可靠组播 reliable multicast  进一步地保证message可靠性，但未保证有序
      - 完整性、有效性和协定的可靠性
    - 有序组播 ordered multicast 进一步地保证message有序性(图示见PPT)。其实就是如何标识各个消息实现消息顺序。
      1. 可靠的FIFO Order  ， 只保证从单个的消息sender看来，自己发送的消息是有序的到达每个receiver。多个sender到达同一receiver的顺序不要求。
         1. 实现算法：如果后发的消息先到，该消息会先buffered
      2. 可靠的Causal Order  ，进一步的，如果多个sender的多个消息之间有因果关系，需要保证这几个消息有序到达同一receiver。多个sender之间没有因果关系的message不要求到达顺序。
         1. 实现算法：
         2. 上述两种，Causal Order隐含了FIFO
      3. 可靠的Total Order，所有sender发出的消息，按发出时间的顺序有序到达所有的receiver.
         1. 实现算法：顺序者 token site算法 和 ISIS算法
         2. FIFO-total hybrid protocol satisfies both FIFO and total orders.
         3. Causal-total hybrid protocol satisfies both Causal and total orders  
         4. 既保证可靠传递，又保证全排序传递的算法，只有在同步的分布式系统中是可能的，在异步的分布式系统中是不可能的。
  - 组播的具体实现算法
    - B-Multicast using unicast sends  B-Multicast using unicast sends  
    - Tree-based multicast ，也就是 IP multicast ；Instead of sending a unicast to all nodes, construct a minimum spanning tree and unicast along that  
    - Gossip  ;No “tree-construction” overhead. More efficient than unicasting to all receivers. Also known as “epidemic multicast”.  
      - Facebook’s distributed datastore uses it to determine group membership and failures.
      - Bitcoin uses it to exchange transaction information between nodes (more later).  

##### 分布式系统中的远程调用（分布式编程的范型）

![中间件层](C:\Users\Jinzhen\Documents\GitHub\CSmarch\jpg\3 计算机系统\中间件层.png)

###### 请求应答协议

###### RPC

###### RMI

IDL：Interface Description Language 接口定义语言

marshalling and unmarshalling 编组和解组，序列化和反序列化

##### 分布式系统中的间接通信

和进程间通信、远程调用的区别是 时间解耦和空间解耦。

- 组通信 group communication，是对组播通信的抽象，可以通过IP组播或一个等价的覆盖网络实现，增加了一些重要特性，比如管理组的成员、检测故障、提供可靠性和顺序保证。（和组播通信muticast 很容易弄混，具体实现可靠性和顺序保证的笔记见 进程间通信-组播通信）
- 发布/订阅模型
- 消息队列

#### 节点间的协调模型。进程之间协调最关键的是协调节点对共享资源的互斥访问，以实现进程同步（多个线程按照逻辑顺序访问共享资源）。保证消息传递message可靠有序（通过组播通信的有序组播）和事件顺序event可确定（通过事件逻辑模型）之后，才有可能协调不同节点上进程的关系，比如互斥，解决互斥的关键算法就是RA算法。节点之间协调还包括中心节点的选举，解决选举的关键算法就是Bully算法。

要建立协调模型，离不开进程间通信技术，尤其是组播通信 multicast，将组播通信进一步抽象，在此基础上实现间接通信技术，组通信 group communication。

##### 分布式系统的互斥算法

- 单机系统下的互斥操作 Mutual exclusion for a single OS ，思路，创造临界区
  • If all processes are running in one OS on a machine(or VM):
  	•信号量 Semaphores
  	•互斥锁 Mutexes
  	•条件变量 Condition variables
  	•监视器锁/管程 Monitors
  	• … 
- 分布式系统下的互斥操作 Mutual exclusion in distributed systems  
  - 只能通过消息传递来实现Processes communicating by passing messages.不能通过共享变量来实现Cannot share variables like semaphores! 如何实现？How do we support mutual exclusion in a distributed system? 

- 互斥算法的非性能特征
  - Safety (essential):• At most one process executes in CS (Critical Section) at any time.
  - Liveness (essential): Every request for a CS is granted eventually.
  - Ordering (desirable): Requests are granted in the order they were made  
  - 容错性，消息丢失时发生什么？进程崩溃时发生什么？
- 互斥算法的性能指标Analyzing Performance  
  - Bandwidth: the total number of messages sent in each enter and exit operation.
  - Client delay: the delay incurred by a process at each enter and exit operation (when no other process is in, or waiting)
    • We will focus on the client delay for the enter operation.
  -  Synchronization delay: the time interval between one process exiting the critical section and the next process entering it (when there is only one process waiting). Measure of the throughput of the system  
- Central server algorithm
  - 算法：Master持有token bucket，管理其他服务器发来的request 组成的queue。
  - 非性能特征：有序性上，看中央服务器接收到request的顺序。
  - 性能：带宽（中央服务器和客户端之间传输令牌），客户端请求延迟（发起令牌请求到获得令牌），客户端之间的同步延迟（客户端A返还令牌给中央服务器，中央服务器分配令牌给客户端B）
  - 缺点： master成为性能瓶颈The master is the performance bottleneck and 和不能避免单点故障single point of failure  ，单点故障可能时中央服务器崩溃，或者持有token的服务器崩溃
- Ring-based algorithm
  - 算法：只有一个token，所有服务器组成ring，轮流持有
  - 非性能特征：并非有序。
  - 性能：token时钟在环上传递，持续消耗带宽。
  - 缺点：不能容忍环上任何一个服务器的崩溃
- Ricart-Agrawala Algorithm
  - 算法：无token，通过因果关系的组播实现互斥访问。进入临界区需要其他进程的应答，**同时发起请求时，由事件的逻辑顺序来确定顺序。**（因此，时间事件的逻辑模型特别重要）
  - 非性能特征：有序。不能容忍节点崩溃。Satisfies safety, liveness, and ordering.  
  - 性能：N个节点组成的系统，每次互斥访问都要求N-1的消息传递
  - 缺点：
- Maekawa Algorithm  
  - 算法：在RA算法上改进，不用获得所有进程的应答，而是获得对等进程组的应答。所有进程组两两之间都有交集。
    - Each process requests permission from only its voting
      set members.
      • Not from all
    - Each process (in a voting set) gives permission to at
      most one process at a time.
      • Not to all  
  - 非性能特征：可以容忍不相关的进程组的崩溃。Satisfies safety, but not liveness and ordering.  
  - 性能：
  - 缺点：

##### 分布式系统的选举算法，选举算法应用较多，比如互斥算法中中央服务器的选择。Raft中leader的选择，所以说选举算法和共识算法密切相关。在同步的分布式系统中，选举算法是满足safety和liveness的，但是在异步的分布式系统中，因为故障检测只能估计，不满足safety和liveness，也就没有完全可靠的选举算法，无法选举出协调者，也就等于无法达成某种共识。

- Ring election algorithm
  - 目标，选举出协调者coordinator，协调者具有最大标识符
  - 算法：每个服务器在选举过程中都有 参与者 和 非参与者两种状态，依照 收到id和自己id的大小关系，已经自己的状态，决定如何传递选举消息
  - 算法分析：容错性很差，每次选举可能要重新开始。
- Bully algorithm  霸道算法
  - 目标，选举出协调者coordinator，协调者具有最大标识符
  - 算法：只向自己已知的具有更大id的服务器发起选举请求
  - 算法分析：具有容错性。
    - In synchronous system model:
      • Set timeout accurately using known bounds on network delays and processing times.
      • Satisfies safety and liveness.
    - **In asynchronous system model:**
      • Failure detectors cannot be both accurate and complete.
      • Either liveness and safety is violated  

##### 分布式系统的共识算法，解决分布式一致性问题（重点中的重点），选举算法就是共识算法的一个扩展

- 共识算法和时间时序算法、选举算法的关系:

  The final value can be decided based on any criteria:
  • Pick minimum of all proposed values.
  • Pick maximum of all proposed values.
  • Pick the majority (with some deterministic tie-breaking rule).
  • **Pick the value proposed by the leader.**
  	• All processes must agree on who the leader is.
  • **If reliable total-order can be achieved, pick the proposed value that gets delivered first.**
  	• All process must agree on the total order.  

- 同步分布式系统的共识算法

  - Dolev and Strong proved that for a system with up to f failures (or faulty processes), at least f+1 rounds of information exchange is required to reach an agreement  

- 异步分布式系统的共识算法
  - 异步系统不可能有完整的一致性算法。We cannot meet both safety and liveness requirements.  
    - Impossibility of consensus in asynchronous systems，
      • 证明：FLP result。 Impossibility of Distributed Consensus with One Faulty Process, FischerLynch-Paterson (FLP), 1985
      • A good enough consensus algorithm for asynchronous systems:
          • Paxos made simple, Leslie Lamport, 2001
              • Other forms of consensus
          • Blockchains
          • Raft (log-based consensus)  
    - Important since consensus is equivalent to many other things
      • Leader election
      • Totally ordered multicast
      • …
      • In practice: design so that guarantees are met if communication delay
      within a bound
      • Otherwise, give up on liveness (eg. Paxos, Raft) or safety  
    - -->Option 1:
      • Let’s set super conservative timeout for a terminating algorithm.
      • Safety violated if a process (or the network) is very, very slow.
    - -->Option 2:
      **• Let’s focus on guaranteeing safety under all possible scenarios.** **Paxos、Raft**
      • If the real situation is not too dire, hopefully the algorithm will terminate  
  - Paxos算法，实现异步系统的分布式一致性的算法。
    - Paxos algorithm:
      • Guarantees safety but not liveness.
      • Hopes to terminate if under good enough conditions.  
    - 算法解决的问题：一台机器可以同时为Proposer, Acceptor和Learner，某些Proposer提出各自的values，怎么使得Acceptor最终采纳其中一个（并且只有一个）value？
    - propose阶段为什么需要一个唯一递增ID？
    - 为什么要多个acceptor？单个有什么问题
    - 即便只有2个提议，某个Acceptor（如图中S3）可能一直都没办法接受一个值，因为前一个提议还没被接受，后一个提议就来了，而且proposal  number还更大，这样前一个的Accept请求就总会失败。最终，S1-S2和S4-S5都接受了某个值，却因为都没有达到大多数（S3没有接受任何一个），导致没有一个value被chosen，**陷入一种Livelock的境况。**
    - 为了解决这个问题，可以通过选举选出一个Distinguish Proposer/Leader，只有这个  Leader可以提议，换句话说，client每次都访问这个Leader，如果访问了其它机器，也会被导回这个Leader.  而其它机器其实就都是Acceptor 和/或 Learner了。而怎么选举、何时选举就有赖于具体的实现算法了。这种选主的策略，除了解决Liveness问题，也可以提高系统的效率。
  - BitCoin的共识算法 -->>分布式记账本
    - Bit consensus: agree on a single bit, based on inputs
      • (0,1,0,0,1,0,0) -> 1  
    - Foundations:
      • Unreliable broadcast using gossip
      • Probabilistic “leader” election for mining blocks (tx ordering)
      • Longest chain rule to ensure long-term consistency / security
      Compared with Paxos/Raft:
      • Scales to thousands of participants, dynamic groups
      • Tens of minutes to successfully log a transaction (vs. milliseconds)  
  - Raft算法 -->> 分布式日志系统
    - Log consensus: agree on contents and order of events in a log
      • {A, B, Q, R, W, Z} -> [A, Q, R, B, Z]  
    - 算法实现：
      - Servers start by electing a leader
         • Sole server habilitated to accept commands from clients
         • Will enter them in its log and forward them to other servers
         • Will tell them when it is safe to apply these log entries to their state machines  
      - Decomposes the problem into three fairly independent subproblems
         • Leader election:
         How servers will pick a—single—leader
         • Log replication:
         How the leader will accept log entries from clients, propagate them to the
         other servers and ensure their logs remain in a consistent state
         • Safety

#### 节点间的并发控制和事务，有了协调模型下的一些算法之后，比如互斥算法，终于可以实现事务性了

##### 分布式事务

理解并发控制的关键：Serially Equivalent  串行等价性，并发执行的结果应该和串行执行的结果一致。

[**ACID里的AID都是数据库的特征,也就是依赖数据库的具体实现.而唯独这个C,实际上它依赖于应用层,也就是依赖于开发者.这里的一致性是指系统从一个正确的状态,迁移到另一个正确的状态.什么叫正确的状态呢?就是当前的状态满足预定的约束就叫做正确的状态.而事务具备ACID里C的特性是说通过事务的AID来保证我们的一致性.**](https://www.zhihu.com/question/31346392)

> Various rules about state of objects must be maintained
> Examples?
> • Class enrollment limit
> • Schedule can’t conflict
> • Account balances have to stay positive
> Consistency must be maintained at end of transaction
> • Checked at commit time, abort if not satisfied  

##### 并发控制

###### 悲观并发控制，锁机制（Java的结构化锁和非结构化锁，数据库的行级锁、页级锁和表级锁）

- ** 两阶段锁 Two phases locking:**
  • Growing phase: new locks acquired, no locks released
  • Shrinking phase: all locks released at once  

  > [两段锁即两阶段锁（Two-phase locking - 2PL）：首先，两阶段锁强调的是“加锁（增长阶段，growing phase）和解锁（缩减阶段，shrinking  phase）这两项操作，且每项操作各自为一个阶段，这就是说不管同一个事务内需要在多少个数据项上加锁，那么所有的加锁操作都只能在同一个阶段完成，在这个阶段内，不允许对对已经加锁的数据项进行解锁操作，即加锁和解锁操作不能交叉执行（同一个事务内）。这一条是说在同一个事务内部的事情。
  >
  > 其次，为了提高并发度，才对锁进行分类，分出**共享锁（读锁）和排它锁（写锁）**，因这两种类型的锁，又产生加两种锁共四种事务之间受影响的情况：
  >
  >  一是先对数据项加共享锁，则此读锁不阻塞其他事务也读取本数据项，这就是说**读读并发**是允许的，即第一种情况；但是此读锁阻塞其他事务写本数据项，这就是说读写并发是不允许的，即第二种情况；这里所说的**读读和读写**的第一个读在前，是因；第二个读或写是可能在其他事务发生的操作，是果，前者（第二个读操作）能够发生后者（写操作）不能够发生。
  >
  > 二是对数据项施加了排它锁，这使得其他事务在这个数据项上的读操作（第三种情况）或写操作（第四种情况）都被禁止。
  >
  > **两阶段的含义是指在同一个事务内，对所涉及的所有数据项进行先加锁，然后才对所有的数据项解锁**。**但两阶段封锁第一阶段加共享锁后影响了其他事务的写操作、加排它锁后影响了其他事务的读操作**（读受影响更不用提写），所以较大地影响了其他事务的运行（**如果不操作相同数据项则互不影响**）。只有第二阶段释放了所有的数据项上的锁之后，才能运行其他要操作相同数据项的事务。](https://blog.csdn.net/weixin_33851177/article/details/92512783)

  - lock promotion 锁的提升，将锁提升为互斥性更强的锁，降低锁的相容性。

- 死锁、死锁解决、死锁检测算法

  - 死锁产生的条件
  - 死锁解决：Timeout: how to set value?
    • Too large -> long delays
    • Too small -> false positives
  - 死锁预防 Deadlock prevention
    • Lock all objects at transaction start
    • Use lock ordering
  - 死锁检测 Deadlock Detection (later)
    • Maintain wait-for graph, look for cycle
    • Abort one transaction in cycle







###### 乐观并发控制

###### 时间戳并发控制

- Assign each transaction a unique timestamp (ts)
  • Serialize transactions according to timestamps
  • Keep track of timestamp last transaction to read and write an object
  • Maintain two invariants:
      • If T writes O, last read and write timestamp must be lower than T’s
      • If T reads O, last write timestamp must be lower than T
      • If T tries to read/write object with higher timestamp, abort and rollback
- ![时间戳并发控制](C:\Users\Jinzhen\Documents\GitHub\CSmarch\jpg\3 计算机系统\时间戳并发控制.png)

##### 原子提交协议（基于锁发展而来）

- 两阶段提交协议 2PC
- 三阶段提交协议 3PC



### 分布式系统的故障模型（检测进程之间的通信问题和同步问题）

- 故障问题有哪些
  - 遗漏故障
    - 进程遗漏故障。进程崩溃 fail
      - 进程故障的故障检测器，利用超时来检测。 ping+ack 或者 心跳检测heartbeat
        - 关键是要完全complete和准确accurate。完全，每个进程故障都能被捕捉到。准确，不能错误认为故障已经发生。
      - 以下为两个进程之间的检测过程。
      - Ping-ack ，需要在网络中发送 2 messages every T units  
        - 如何量化判断两个进程之间出现故障？求超时时间∆1 如何设置
          - 同步的分布式系统 synchronous。单次ping-ack就行, ∆1 = 2(max network delay)  ，超过2x网络最大延迟，没有收到ack，进程故障
          - 异步的分布式系统 asynchronous。参考观察到的最大值  ∆1 = k(max observed round trip time)  ，**只能估计。**
        - 最坏情况下，从故障出现，到故障发现，间隔多久？（具体见UIUC 的slide)
          - 不管是同步还是异步，假设∆是上一次ping发出和ack返回间隔的时间，t + T +∆ 1 - ( t + ∆ ) = T + ∆1-  ∆	  
      - heart-beat，需要在网络中发送 1 message every T units.  
        - 如何量化判断两个进程之间出现故障？求超时时间∆2如何设置
          - synchronous,  每隔T发送一次heartbeat, 最坏情况下，两次接收的间隔是
            - ( t + T  + max network delay）- ( t + min network delay ) = T + ∆2 
            - ∆2 = max-min
          - asynchronous, ∆1 = k(max observed round trip time)  ，**只能估计。**
        - 最坏情况下，从故障出现，到故障发现，间隔多久？
          - ∆ + T + ∆2   
          - 具体而言，异步可能比同步久得多，因为异步执行，无法知道对方什么时候可以执行结束。
        - 问题来了，heartbeat 如何扩展到多个？？？
        - How do we extend to a system with multiple processes?
          - Centralized heartbeating: not complete. 
            - 缺点：不能克服中心节点可能失效的问题，中心节点的单点故障不能检测
          - Ring heartbeating: not entirely complete. 
            - 缺点：不能克服多点失效的问题 Multiple failures ，多点失效时，无法判断环上是哪几个节点失效 Ring repair overhead
          - All-to-all: complete, but more bandwidth usage.  
            - 缺点：带宽耗费高
            - 改进：每个节点，根据和其他节点的延迟[min, max]，选择能最快发现自己故障的节点发送心跳。
      - trade-off
        - 缩短检测周期，将会增加网络带宽的消耗。Decreasing T decreases failure detection time, but increases bandwidth usage.  
        - 增加超时时间，减少了检测出错的可能，但也增加了故障发生到发现故障的时间差。Increasing ∆1 or ∆2 increases accuracy but also increases failure detection time.  
    - 通信遗漏故障。通信信道communication channel 出错
      - 通信故障，采用网络协议来补偿。Message drops (or omissions) can be mitigated by network protocols  
  - 随机故障（拜占庭故障），最为严重的一种
  - 时序故障，同步分布式系统会出现的故障。
- 故障屏蔽，将随机故障转化为遗漏故障

### 分布式系统的安全模型

- 保护对象，保护进程和进程交互过程（也就是通信过程）
- 威胁
  - 对进程的威胁
    - 客户机
    - 服务器
      - 比如洪泛攻击，要采用拒绝服务的方法解决
      - 比如移动代码，典型的就是SQL注入
  - 对通信通道的威胁
    - 中间人攻击，伪造消息。HTTP-HTTPS
- 安全手段
  - 密码学，加密与解密
    - 权限认证
  - 安全信道

### CAP理论 - 一致性/可用性权衡



## 如何设计一个分布式系统？

### 首先，这个分布式系统是一个什么类型的分布式系统？数据存储，计算，文件系统，邮件系统，分类帐还是应用程序？

- 数据存储：分布式数据库、分布式缓存
  - 分布式数据系统大概的模型
    - 节点，一个可以独立按照分布式协议完成一组逻辑的程序个体。在具体的工程项目中，一个
      节点往往是一个操作系统上的进程。
    - 节点之间的通信
    - 存储

      - 数据分布

        - 数据分布方式

      - 数据副本

        - 数据副本协议

    - 计算

      - 本地化计算
    - bitcoin, 分布式记账本，这部分内容忽略
- 计算：分布式计算系统
- 文件系统：分布式文件系统
- 应用程序：分布式软件系统



### 分布式存储系统

#### 分布式哈希表 Distributed Hash Table， 分布式地寻址和存储

   两个key point：每个节点只维护一部分路由；**每个节点只存储一部分数据。从而实现整个网络中的寻址和存储。**

   DHT只是一个概念，提出了这样一种网络模型。并且说明它是对分布式存储很有好处的。但具体怎么实现，并不是DHT的范畴。

##### Centralized  中心化的算法

##### Ring 环形的算法

##### Clique 的算法

#####  **一致性哈希：** 是DHT的一种实现。

​    本质还是一个哈希算法。回想平时我们做负载均衡，按querystring签名对后端节点取模是最简单也是最常用的算法，但节点的增删后所造成的问题显而易见，原有的请求几乎都落不到同一台机器上。优化一点的是carp算法(用机器ip和query一起做hash，选取hash值最小的一台)，只让1/n的数据受到影响。

   一致性哈希，似乎最早提出是在分布式缓存里面的，让节点震荡的时候，影响最小。不过现在已经应用在分布式存储和p2p系统里面。

  一致性哈希也只是提出四个概念和原则，并没有提及具体实现：

  1、balance：哈希结果尽可能的平均分散到各个节点上，使得每个节点都能得到充分利用。

  2、Monotonicity：单调性。如果是用签名取模算法，节点变更会使得整个网络的映射关系更改。如果是carp，会使得1/n的映射关系更改。一致性哈希的目标，是节点变更，不会改变网络的映射关系。

  3、spread：同一份数据，存储到不同的节点上，换言之就是系统冗余。一致性哈希致力于降低系统冗度。

  4、load：负载分散，和balance其实是差不多的意思，不过这里更多是指数据存储的均衡，balance是指访的均衡。

- **Chord算法**

O(log(N)) memory and lookup costs
• Hashing to distribute filenames uniformly across key/address space
• Allows dynamic addition/deletion of nodes  （Finger Table）

- **KAD**算法(Kademlia)

Many DHT designs
• Chord, Pastry, Tapestry, Koorde, CAN, Viceroy, Kelips, Kademlia, …
Slow adoption in real world
• Most real-world P2P systems unstructured
    • No guarantees
    • Controlled flooding for routing
• **Kademlia slowly made inroads, now used in many file sharing networks**
Distributed key-value stores adopt some of the ideas of DHTs
• Dynamo, Cassandra, etc.  

#### 分布式共享内存 DSM

#### 持久分布式对象存储

#### 分布式文件系统



### 分布式计算系统

### 分布式Web

###     系统如何拆分为子系统？

###     如何规划子系统间的通信？

-     MQ 框架标准化了不同应用程序间非实时异步通信的方式。
-     RPC 框架标准化了不同应用程序间实时通讯的方式。
-     DAL（Data Access Layer，数据访问层）框架标准化了应用程序和数据库之间通讯的方式。

###     如何让子系统可以扩展？

###     子系统的可靠性如何保证？

###     通信过程中的安全如何考虑？

###     数据的一致性是如何实现的？

- 分布式存储

	- 数据库分库分表问题
	- 分布式存储中的
数据检索问题
	- 分布式缓存
	- Dubbo
	- ZooKeeper

- 分布式计算

*XMind: ZEN - Trial Version*